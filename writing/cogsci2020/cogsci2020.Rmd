---
title: "Child language input does not reflect word frequency: Typical and atypical feature description across development"
bibliography: purple-carrots.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

abstract: >
    Language provides children a powerful source of information about the world. Blind children learn the same kinds of relationships among visual categories as sighted children, without any of the relevant visual input (Landau & Gleitman, 1985). However, language does not perfectly reflect the world: the most typical features of natural kinds may often go unremarked. For instance, adults rarely describe the color of an orange carrot, as world knowledge makes this description redundant. Given children’s nascent world knowledge, does parents’ speech to children follow this pattern? From longitudinal corpus data of parent-child communication (Goldin-Meadow et al., 2014) between 14–58 months, we extracted usage data for 684 high-frequency concrete nouns and co-occurring adjectives. Independent raters coded the typicality of over 2,000 unique adjective–noun pairs on a 7-point Likert scale. If language statistics reflect world statistics, description should be dominated by the typical (strong negative skew); however, across all ages, we see descriptors concentrated in the atypical range (positive skewness = 0.65). However, parents were reliably more likely to use typical descriptors when talking to younger copmared with older children. Overall, child language input reflects notable more than typical features, but increased description of typical features early in development may provide a foothold for young learners.

keywords: >
    language input, language acquisition, child-directed speech
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo = F, warning = F, cache = T, 
                      message = F, sanitize = T)
# Note: to build, 
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(here)
library(tidyverse)
library(ggridges)
library(scales)
library(tidyboot)
library(xtable)
library(papaja)
library(lme4)
library(lmerTest)
library(broom.mixed)
```

Children learn a tremendous amount about the structure of the world around them in just a few short years, from the rules that govern the movement of physical objects to the hierarchical structure of natural categories and even relational structures among social and cultural groups [@baillargeon1994; @rogers2004; @legare2016]. Where does the information for this rapid acquisition come from? Undoubtedly, a sizeable component comes from direct experience observing and interacting with the world [@sloutsky2004; @stahl2015]. But another important source of information comes from the language people use to talk about the world [@landauer1997; @rhodes2012]. For many of the things children learn about--like the roundness of the earth--the information must come from language [@harris2006]. How similar is the information available from children's direct experience to the information available in the language children hear? 

Two lines of work suggest that they may be surprisingly similar. One compelling area of work is the comparison of semantic structures learned by congentinally blind children to those of their sighted peers. In several domains that would at first blush rely heavily on visual information, such as color terms or verbs of visual perception (e.g. *look*, *see*), blind children's semantic similarity judgments are quite similar to those of sighted children [@landau2009]. Further, blind adults' judgments of visual perception verbs are sensitive to highly detailed information like variation in intensity (e.g. blaze vs. glow), just like sighted adults [@bedny2019]. A second line of evidence supporting the similarity of information in perception and language is the broad success of statistical models trained on language alone in approximating human judgments across a variety of domains [@landauer1997; @mikolov2013; @devlin2018]. Even more compellingly, models trained on both linguistic usage and perceptual features for some words can infer the perceptual features of linguistically related words entirely from the covariation of language and perception [@johns2012]. 

Still, there is reason to believe that some semantic features may be harder to learn from language than these data suggest. While the co-occurrence structure of language may provide strong clues that carrots are like tomatoes, carrots are vegetables, and carrots are eaten for dinner, they may provide very little evidence that carrots are orange [@willits2008]. This is because people rarely use language merely to provide running comentary on the world around them. Instead, we use language to talk about things we find interesting--things that are surprising, exciting, or otherwise divergent from our conversational partners' expectations [@grice1975]. 

Thus, speakers are informative in relation to common knowledge with their conversational partner and available information in the environment, not redundant with these other sources of knowledge. Communication tasks in the lab largely bolster this claim, finding that people avoid being over- or under-informative when they speak (Mangold & Pobel, 1988; MORE CITES) and interpret others' speech as if they are doing the same (CITES). In particular, speakers are informative in relation to both the context of objects in the environment and the typical features of those objects (Mitchell et al., 2013; Westerbeek et al., 2015; Rubio-Fernandez, 2016). While speakers overwhelmingly refer to an object that is typical of its category with a bare noun—e.g., calling a yellow banana "a banana"—they often describe more about the object's features when they are atypical, rarely referring to a green or blue banana without specifying its color. Listeners are similarly affected by color description, expecting a color adjective to be used when an object's color is atypical [@sedivy2003].

For things like carrots--that children learn about both from perception and from language--this issue may be resolved by integrating both sources of information: Likely almost all of the carrots they see are orange even if no one comments on them. But for things for which they lack perceptual access--zoo animals, other social groups, and so on--the structure of language alone may lead them to have distorted categories. This may be especially problematic because children's understanding of the pragmatics of adjective use change significantly over development [@horowitz2016]. 

Should we expect children's categories to be biased in this way, with typical features underrepresented and atypical features overrepresented? We examine the typicality of adjectives in a large, diverse corpus of parent-child ineractions recorded in children's homes to ask whether parents talking to their children--just like adults speaking and writing--tend to use adjectives predominantly to mark atypical features. We find that they do: parents and children overwhelmingly choose to mention atypical rather than typical features. However, we also find that parents use adjectives differently over the course of children's development, noting typical features more often to younger children. We then ask whether the co-occurrence structure of language nonetheless captures typicality information, and find that relatively little of it is represented. Thus, children must either have distorted representations of categories learned only through language or else learn typicality through other means.



**notes for intro word2vec more**

If caregivers use language to mirror the world or to teach their children about the typical features of things, they should often use highly typical adjectives to describe nouns. If, on the other hand, they speak informatively to convey what is atypical or surprising in relation to their own sophisticated world knowledge, they should more often mention the atypical features of things. 

Information in language goes beyond what can be learned from any one utterance. Though one might never hear the words /kumquat/ and /grapefruit/ in the same sentence, their common contexts—other words like /eat/, /rind/, /tree/, /tart/, and /seeds/—are clues that they have some similarities. Models of distributional semantics capitalize on these patterns by representing words using their contexts, and judging two words to be similar if they are surrounded by similar sets of words. Though we found that children get more information about atypical than typical features of objects on the utterance level, perhaps patterns of language use across many utterances could be used to extract typical feature information. 




<!-- While such effects have been demonstrated in the lab, the extent to which these language pressures structure naturalistic language remains unclear. A recent analysis of co-occuring adjective-noun pairs in the Wikipedia corpus asked human raters to judge the whether a given adjective was 'always true', 'sometimes true', or 'never true/unrelated' to a co-occuring noun (Willits,// *personal communication * // ? ). The analysis revealed that language usage is dominated by descriptions that are only 'sometimes true' of the described category, and thus suggests that naturalistic language usage reflects pressures to comment on the atypical (Willits,// *personal communication * // ? ). -->

<!-- If the information in language statistics is indeed not a reflection of world statistics, young children may be faced with a difficult learning problem. Language provides a crucial information source for young children to learn about the complex world around them [@landauer1997; @rhodes2012]. Without the relevant world knowledge, young children learning from language input that is biased to overrepresent atypical features could develop inaccurate or distorted understandings of the categories being described.  -->



<!-- It could be that the language input to young children is far different from language on Wikipedia, such that children are learning from language that more directly reflects information about the world around them.  Child-directed speech (CDS) differs from typical adult-directed speech along a number of structural dimensions, having simpler syntax and more reduplications (Snow, 1972). The current study asks whether CDS is biased to highlight atypical features, as in adult speech (WILLITS, personal communication), or to more veridically reflect typical information about the world. -->

<!-- We first asked how information is distributed in CDS, and how similar it is to ADS. In a longitudinal corpus of parent-child communication, we collected usage data for adjective-noun pairs that co-occur within the same utterance. Human raters on Amazon Mechanical Turk then judged typicality (e.g., "How common is it for a banana to be a yellow banana?") on a 7-point scale. Using these data, we first demonstrate that child-directed speech (even to children as young as 14 months) is dominated by descriptions of lower-typicality features (e.g., "green banana"), rather than potentially redundant highly-typical features (e.g., "yellow banana").  -->

<!-- CDS also changes across development, with parents modulating the way they talk as a function of child's age (Snow, 1972). It is plausible that caregivers, especially of young children, would provide more description of typical features, whether simply to communicate effectively with a child who has less world knowledge or to explicitly teach their child about the world. This would suggest children with the least developed world knowledge actually get more information about aspects of the world that are typically true. -->

<!-- To address this possibility, we next asked if the kind of information in CDS changes as children develop. We find evidence that description changes across development, with young children hearing relatively more talk about highly-typical features compared with older children. -->

<!-- We lastly discuss what these data may imply for the developing learner. Children rapidly develop rich conceptual repetoires, yet the language children hear seems biased to overrepresent certain features. We consider a few potential cues that could allow children to extract better typicality information from language, such as tracking second-order co-occurence or syntactic cues.  -->


# Adjective typicality

In order to determine whether parents use adjectives mostly to mark atypical features of categories, we analyzed caregiver speech from a large corpus of parent-child interactions recorded in the home. We extracted all adjective-noun combinations for concrete nouns, and asked a sample of Amazon Mechanical Turkers to judge how typical the property described by each adjective was for the noun it modified. We then examined both the broad features of this typicality distribution and how it changed over development.


## Corpus

We used data from the Language Development Project--a large-scale, longitudinal corpus of parent child-interactions recorded in children's homes. Families were recruited to be representative of the Chicagoland area in both socio-economic and racial composition (Goldin-Meadow et al., 2014). Recordings were taken in the home every 4-months from when the child was 14-months-old until they were 58-months-old, resulting in 12 timepoints. Each recording was of a 90-minute session in which parents and children were free to behave as they liked and interact as much or as little as they liked.

Our sample consistend of all N typically-developing children and their parents, who were recorded for at least M timepoints. Together, this resulted in a total of 828,392 distinct parent utterances. **SHOULD DO THIS IN CODE** 

## Stimulus Selection

From these utterances, we extract all of the nouns (using part of speech tags--**MANUAL? AUTOMATIC**). Because of our interest in the change in speech of development, we considered only nouns that appeared at least once every 3 sessions (i.e. per developmental year). This yielded a set of some 2,000 potential target nouns (**how many did we lose?**).

<!-- To determine the extant information structure in children's language input, we subset the corpus to only caregiver speech, yielding a set of 828,392 distinct utterances. While it is important to consider children's own productions as an integral part their language environments (CITATION), description of a concept relies heavily on  linguisitic and world knowledge, and so it is necessary to analyze caregiver speech separately. For example, at our earliest timepoint (14-months), children are not producing multiword utterances with adjectives and nouns, or even reliably producing many adjectives at all.   -->

We selected from the corpus all N utterances containing any of these nouns and any word tagged as an adjective. We considered for analysis all adjective-noun pairs that occurred in any utterance (i.e. utterances with one noun and three adjectives were coded as three pairs ). This set contained a number of high-frequency idiomatic pairs whose typicality was difficult to classify (e.g., "good"--"job"; "little"--"bit"). To resolve this issue, we used human judgments of words' concreteness to identify and exclude candidate idioms [@brysbaert2014]. We retained for analysis only pairs where both the adjective and noun were in the top 25% of the concreteness ratings. **GIVE EXAMPLES, SAY HOW MANY**.  Finally, all pairs were given to 7 human coders to judge whether the pair was "incoherent or unrelated" and we thus excluded a further XXX pairs from the sample (e.g., incoherent pairs such as "wet" -- "brown", and presumably errorfully coded pairs such as "orange" -- "orange").

Thus, our final sample included 2,220 unique adjective-noun pairs drawn from over 6,000 utterances. The pairs were combinations of 684 distinct concrete nouns and 118 distinct concrete adjectives. We compiled these pairs and collected human judgments on Amazon Mechanical Turk for each pair, as described below. Table  \ref{tab:utt_table} contains example utterances from the final set and typicality judgments from our human raters.


```{r utt_table, results="asis"}
tab <- tibble(utterance = c("especially with wooden shoes",
                            "some of our green bananas too", 
                            "are bananas yellow?"),
              pair = c("wooden-shoe", "green-banana", "yellow-banana"),
              `rating 1` = c(2, 4, 5),
              `rating 2` = c(2, 3, 5),
              `rating 3` = c(3, 5, 7),
              `rating 4` = c(2, 3, 6),
              `mean typicality` = c(2.75, 3.75, 5.75))


print(xtable(tab, display = c("s", "s", "s", "d", "d", "d", "d", "f"),
             caption = "Sample typicality ratings from 4 human coders for three adjective-noun pairs drawn from the corpus."), 
      type = "latex", comment = F, table.placement = "tb", floating = TRUE,
      floating.environment = "table*",
      include.rownames = FALSE)
```


## Participants

Each participant rated 20 pairs, and each pair was rated by four participants; we used Dallinger [CITE], a tool for automating complex recruitment on Amazon Mechanical Turk, to balance recruitment. Overall, we recruited 444 participants to rate 2200 adjective–noun pairs. After exclusions using an attention check, we retained 8580 judgments, with each adjective–noun pair retaining at least two judgments.

## Design and Procedure

To evaluate the typicality of the adjective–noun pairs pulled from the corpus, we asked participants on Amazon Mechanical Turk to rate each pair. Participants were presented with a question of the form “How common is it for a cow to be a brown cow?” and asked to provide a rating on a seven-point scale: (1) never, (2) rarely, (3) sometimes, (4) about half the time, (5) often, (6) almost always, (7) always. 


```{r distribution_plot, fig.height = 6, fig.width=3.6, fig.align = "center", num.cols.cap=1, fig.cap = "Denisity plots showing the usage amount at each timepoint based on the typicality of the adj-noun pair."}
full_turk_counts <- read_csv(here("data/judgments_session.csv"))

full_turk_counts_plot <- full_turk_counts
full_turk_counts_plot$session2 <- cut(full_turk_counts_plot$session, 
                   breaks=c(0, 2, 4, 6, 8, 10, 12),
                   labels = c(14, 22, 30, 38, 42, 50))
                   # breaks=c(0, 3, 6, 9, 12, 10, 12))

full_expanded <- full_turk_counts[rep(row.names(full_turk_counts), full_turk_counts$n), 1:17]

full_expanded %>%
  mutate(typicality=mean_typ) %>%
  mutate(age = (4*session + 10)) %>%
  # filter(age <= 38) %>%
  group_by(session) %>%
  mutate(age=min(age)) %>% 
  ggplot(aes(x=as.numeric(typicality), y=age, group=age, fill=age)) +
  geom_density_ridges2() +
  ylab("Child Age (months)") +
  xlab("More Atypical                   More Typical \n Typicality of adjective-noun pairs") +
   geom_vline(xintercept = 4)+
  theme_minimal() +
  scale_fill_gradient(low="cornsilk", high=muted("red")) +
  theme(panel.grid = element_line(color="lightgrey",size=0.5), 
    axis.line = element_line(colour = "black"),
    axis.ticks = element_line(),
    axis.text.x = element_text(size=12, angle=28, hjust=1),
    axis.text.y = element_text(size=12),
    legend.position = "none") +
  # scale_x_continuous(minor_breaks = seq(1 , 7, 1), breaks = seq(1, 7, 1))+
  scale_x_continuous(minor_breaks = seq(1 , 7, 1), breaks = seq(1, 7, 1), labels = c('never', 'rarely', 'sometimes', 'about half', 'often', 'almost always', 'always')) +
  scale_y_continuous(minor_breaks = seq(14, 58, 4), breaks = seq(14, 58, 4))
```

```{r models}
model_judgments <- read_csv(here("data/all_judgments.csv"))

tidy_turk_counts <- full_turk_counts %>%
    select(-range, -mean_typ, -noun_stem, -adj_stem, -attncheckscore) %>%
    pivot_longer(cols = x1:x5, names_to = "rater", values_to = "score") %>%
    mutate(offset = 4,
           age = 10 + 4 * session,
           article = case_when(is.na(article) ~ "",
                               article %in% c("a","an") ~ "a/an",
                               T ~ "the"))

tidy_turk_counts <- tidy_turk_counts %>%
  left_join(model_judgments, by = c("adj","noun"))

tidy_turk_counts_for_plots <- tidy_turk_counts %>%
  distinct(noun,adj,turker_judgment,ldp_similarity,wiki_similarity)





token_weight <- lmer(score ~ log(age) + (1|noun) + (1|network_id),
                     offset = offset, 
                     weights = n,
                     data = tidy_turk_counts) %>%
                     tidy() %>%
                     filter(effect == "fixed")


type_weight <- lmer(score ~ log(age) + (1|noun) + (1|network_id),
                     offset = offset, 
                     data = tidy_turk_counts) %>%
                     tidy() %>%
                     filter(effect == "fixed")

```


```{r word2vec-pairs, include = FALSE, eval = FALSE}
pairs <- tidy_turk_counts %>%
    group_by(noun, adj) %>%
    summarise(typicality = mean(score, na.rm = TRUE)) %>%
    group_by(noun) %>%
    mutate(max_typ = max(typicality),
           min_typ = min(typicality)) %>%
    distinct(noun, min_typ, max_typ) %>%
    filter(min_typ != max_typ, max_typ >= 5, min_typ <= 3)

high_low_pairs <- tidy_turk_counts_for_plots %>%
  filter(noun %in% pairs$noun) %>%
  filter(turker_judgment <= 3 | turker_judgment >= 5) %>%
  group_by(noun) %>%
  arrange(desc(turker_judgment))




# filter to prenominals?

# tidy_turk_pairs <- tidy_turk_counts %>%
#     filter(noun %in% pairs$noun) %>%
#     group_by(noun, adj) %>%
#     filter(typicality <= 3 | typicality >= 5) %>%
#     group_by(noun) %>%
#     arrange(desc(typicality)) 
    #slice(c(1, n())) %>%
    #mutate(n = 1:n()) %>%
    #spread(n, adj)


```

## Results

<!-- set up the null better -- I think here. If we put it earlier people will forget? -->

If description in child-directed speech mirrors adult-directed speech, we should see that caregiver description is dominated by modifiers that are sometimes true of the noun they modify. If instead child-directed speech privledges redundant or assumed information, caregiver description should yield a distinct distribution dominated by highly typical modifiers. As can be seen in figure \ref{fig:distribution_plot}, there is remarkable developmental consistency: caregiver description largely focuses on features that are only sometimes true of the concept.

### Developmental Consistency.

A mixed effects model predicting typicality from usage confirms that caregiver speech is signficantly biased toward description of atypical speech (*B* XXX, *p* < YYY). The full mixed effects model included random effects of noun and rater, specified as follows `lmer(typicality ~ log(age) + (1|noun) + (1|rater)` using an offset of 4 which is the midpoint of our scale. Rather than focusing on typical information, caregiver language tends on average be about less typical features (i.e. 'sometimes', 'rarely' or 'never').

Examining usage data as a function of typicality (see figure \ref{fig:distribution_plot}), we see evidence of a positive skew (0.65). Data from every time point from 14-58 months seems to show a similar pattern (skews 0.23 - 0.82). These skews provide further evidence that the the bulk of caregiver language reflects lower-typicality adjective-noun pairs.

Our mixed effects model also yields some evidence of developmental change. There is a negative effect of age on typicality (*B* XXX, *p* < YYY), suggesting that children's language environments become increasingly focused on atypicial features as they get older. This result is discussed further below.


### Adult to adult Speech.

Next, we briefly confirm that adult to adult speech shows the similar usage pattern using an identical analysis framework on usage data from the Corpus of Contemporary American English (COCA). Using the set of adjective-noun pairs for which we have judgments from our analysis of caregiver speech, we repeat our analysis of usage frequencies for a set of 1,357 distinct adjective-noun pairs. 

As predicted, an identical mixed effects model predicting typicality from usage shows that adult-directed speech speech is significantly biased toward description of atypical features (*B* XXX, *p* < YYY ). ADS also shows a similar a positive skew (0.68), such that the bulk of language reflects adjective-noun pairs rated < 4 on typicality (i.e. 'sometimes', 'rarely' or 'never'). 

The usage distributions in adult-directed speech seem qualitatively similar to the distributions we found in child-directed speech. In sum, these data suggest that even when talking with very young children, caregiver speech structures information similarly to adult-directed speech.

The difference of settings makes it difficult to compare these data directly with our data from the Language Development Project corpus. Four of the COCA datasets are drawn from written texts, which puts in place distinct language pressures and removes visual common ground. While there is one subset of the corpus drawn from spoken data, those utterances come from TV and radio programs. All of these settings are likely quite different environements for language than the naturalistic in-home setting that our Language Development Project corpus draws from. In light of these differences, any observed similarity in usage seems remarkable.



### Child Speech.

What kind of information is contained in children's own speech? By analyzing children's own utterances, we can determine when children come to use description in a way that looks like caregiver speech. Are children mirroring adult-like uses of description even from a young age, or are they choosing to describe more typical features of the world?

The Language Development Corpus contains 442,048 child utterances. Using the set of adjective-noun pairs for which we have judgments from our analysis of caregiver speech, we repeat our analysis on usage data for a set of 533 distinct adjective-noun pairs. 

While preliminary, an identical mixed effects model predicting typicality from usage shows that children's speech is signficantly biased toward description of atypical features (*B* XXX, *p* < YYY ). Mirroring caregiver and adult-adult speech, children's productions show a positive skew (0.61, comapre with skewness = 0.65 seen in the adults), such that the bulk of language reflects adjective-noun pairs rated < 4 on typicality (i.e. 'sometimes', 'rarely' or 'never').



### Talk about the Highly-Typical.

Though there is striking consistency of description in caregiver speech across development, our mixed effects model revealed a negative effect of age. In line with our hypotheses, it seems that caregivers are more likely to provide description of typical features for their young children, compared with older children. 

Indeed, when we look at the proportion of all description that is about highly-typical features (i.e. features that are 'often', 'almost always', or 'always' true), we see a significant negative correlation with age (*r* = -0.8231762, p < 0.01). While children at all ages hear more talk about what is atypically true (see figure \ref{fig:distribution_plot}), younger children hear relatively more talk about what is typically true than older children do (figure \ref{fig:prototypical_plot}).


```{r prototypical_plot, fig.width=3.6, fig.align = "center", num.cols.cap=1, fig.cap = "This plot shows the proportion of caregiver description that is about typically-true features, as a function of age."}
#look for prototypicals
#  defined as anything 5 or higher, "somewhat typical" to "extremely  typical"
prototypicals <- full_expanded %>%
  mutate(age = (4*session + 10)) %>%
  mutate(typicality=mean_typ) %>%
  group_by(age, typicality) %>%
  summarize(sum=n()) %>%
  mutate(howTyp = if_else(typicality>=5, T, F)) %>%
  group_by(age, howTyp) %>%
  summarize(sum=sum(sum)) %>%
  mutate(prop=sum/sum(sum)) %>%
  filter(howTyp)

prototypicals %>%
  ggplot(aes(x=age,y=prop, colour=age)) +
  geom_smooth(method= loess, color= "black")+
  geom_point(aes(fill=age), colour="black",pch=21, size=5) +
  ylab("Proportion of modifiers that rated as \n typical of modified noun") +
  xlab("Child's Age (months)") +
  scale_x_continuous(minor_breaks = seq(14, 58, 4), breaks = seq(14, 58, 4))+
  theme_minimal() +
  scale_fill_gradient(low="cornsilk", high=muted("red")) +
  theme(axis.line = element_line(colour = "black"),
        axis.ticks = element_line(),
        axis.text = element_text(size=14),
        panel.grid = element_line(color="lightgrey",size=0.5),
        axis.text.x = element_text(size=10, angle=15),
        legend.position = "none") 
```

## Discussion

In sum, language is used to discuss atypical, rather than typical, features of the world. Description in caregiver speech seems to largely mirror the usage patterns that we observed in adult-adult speech, suggesting that these patterns arise from general communication pressures. Indeed, even children's own productions show a similar usage pattern, with more description of atypical features of the world as early as we can measure.

It should be noted that children's utterances come from naturalistic conversations with caregivers, and their pattern of description is likely highly dependent on that caregiver's utterances. That is, if a parent chooses to describe the *purpleness* of a cat in book, the child may well respond by asking about that same feature. Thus, it is possible that some of the children's use of atypical description is prompted by a parent-led discourse. Future analyses would need to better disentangle the extent to which children's productions are imitative of caregivers. 

While children's own descriptions largely mirror adults', we do see some evidence that children's linguistic environment changes across development, becoming increasingly focused on atypical features. The higher prevalance of typical descriptors in early development may help young learners; however, even at the earliest point we measured, the vast majority of language input describes atypical features. 

Across adult, parent, and child language corpora, we find robust evidence that language use systematically overerpresents atypical features. This usage aligns with the idea that language is used informatively in relation to background knowledge about the world. It may pose a problem, however, for young language learners with still-developing world knowledge. If language does not transparently convey the typical features of objects, and instead (perhaps misleadingly) notes the atypical ones, how might children come to learn what objects are typically like? One possibility is that information about typical features is captured in regularities across many utterances. If this is true, language may still be an important source of information about typicality as children may be able to extract more accurate typicality information by tracking second-order co-occurence.


# Other Ways of Extracting Structure from Language

Much information can be gleaned from language that does not seem available at first glance. From language alone, simple distributional learning models can recover enough information to perform comparably to non-native college applicants on the TOEFL (Landauer & Dumais, 1997). Recently, Lewis et al. (2019) demonstrated that even nuanced feature information may be learnable through distributional semantics alone, without any complex inferential machinery. We take a similar approach to ask whether a distributional semantics model trained on the language children hear can capture typical feature information.


### Word2Vec

To test this possibility, we trained word2vec, a model that predicts words using their contexts, on the same corpus of child-directed speech used in our first set of analyses. Our model is a continuous-bag-of-words word2vec model trained using the package gensim [CITE]. If the model captures information about the typical features of objects, we should see that the model's word pair similarities are correlated with the typicality ratings we elicited from human raters.  

### Results

We find that similarities in the model have near zero correlation with human adjective–noun typicality ratings (r = 0.018). This is in spite of better correlations with large sets of human similarity judgments between different kinds of word pairs (correlation with  wordsim353, 0.37; correlation with simlex, 0.15). This suggests that statistical patterns in child-directed speech are likely insufficient to encode information about the typical features of objects, despite encoding at least some information about word meaning more broadly. However, the corpus on which we trained this model was small; perhaps our model did not get enough language to draw out the patterns that would reflect the typical features of objects. To test this possibility, we asked whether word vectors trained on a much larger corpus—English Wikipedia—strongly correlate with typicality ratings. We find that while the correlation between similarities in the Wikipedia–trained model and human noun–adjective typicality ratings is stronger, it is still fairly weak at r = 0.24. Strikingly, the correlation between similarities in our model and similarities in the Wikipedia-trained models is stronger (r = 0.33) than either model's correlations with human judgments. This suggests that these models are picking up on some systematic associations between nouns and adjectives, but not typical ones. Overall, these results suggest that models of distributional semantics fail to extract typical feature information from language in which atypical features are more often described.

```{r word2vec1, fig.align='center', fig.width = 4, set.cap.width=T, num.cols.cap=1, fig.cap = "Correlation between vector similarities in word2vec (trained on the LDP corpus) and human-rated typicality judgments for our noun-adjective pairs."}
#img <- png::readPNG(here("writing/cogsci2020/figs/word2vec.png"))
tidy_turk_counts_for_plots %>%
  ggplot() +
  geom_jitter(aes(turker_judgment, ldp_similarity), width = 0.4, height = 0.4, size = 0.1) +
  ylab("Similarity in Word2Vec trained on LDP") +
  xlab("Typicality rating from human participants")


#tidy_turk_counts_for_plots %>%
 # group_by(noun,adj) %>%
  #ggplot() +
  #geom_jitter(aes(turker_judgment, wiki_similarity), width = 0.4, height = 0.4, size = 0.1) 
#grid::grid.raster(img)
```


```{r word2vec2, fig.align='center', fig.width = 4, set.cap.width=T, num.cols.cap=1, fig.cap = "Correlation between vector similarities in word2vec trained on the LDP corpus and vector similarities in word2vec trained on English Wikipedia for our noun-adjective pairs."}

tidy_turk_counts_for_plots %>%
  group_by(noun,adj) %>%
  ggplot() +
  geom_jitter(aes(ldp_similarity, wiki_similarity), width = 0.4, height = 0.4, size = 0.1) +
  ylab("Similarity in Word2Vec trained on LDP") +
  xlab("Similarity in Word2Vec trained on Wikipedia")

```

<!-- ## Age of Acquisition -->

<!-- Given our finding that young children hear relatively more description of typical features, it could be that linguistic input is more helpfully structured for the developing learner if we have a more nuanced measure linguistic experience. For example, one possibility is that caregivers are selectively overdescribing (or at least describing typical features) of concepts unfamiliar to their child. This possibility makes a clear prediction: namely, that information in CDS to children at a given age may differ as a function of whether the child knows the word being described, or not.  -->

<!-- To address this question we combined age of acquisition data from Wordbank and from adult-generated recollections (Kuperman et al., 2012).  -->



```{r kid_plot, include=FALSE, fig.height = 5.5, fig.width=3.6, fig.align = "center", num.cols.cap=1, fig.cap = "Analyzing child productions, these denisity plots show the usage amount at each timepoint based on the typicality of the adj-noun pair. Note that at our earliest timepoints (14 and 18 months), children were not reliably producing enough utterances with adjectives and nouns to be included here."}
kid_production <- read.csv("../../data/kid_production.csv")

kid_production %>%
  mutate(typicality=mean_typ) %>%
  mutate(age = session) %>%
  mutate(age = (4*session + 10)) %>%
  ggplot( aes(x=as.numeric(typicality), y=age, group=age, fill=age)) +
  geom_density_ridges2() +
  ylab("Child Age (months)") +
  xlab("More Atypical                   More Typical \n Typicality of adjective-noun pairs") +
  theme_minimal() +
  scale_fill_gradient(low="cornsilk", high=muted("purple")) +
  theme(panel.grid = element_line(color="lightgrey",size=0.5),
    axis.line = element_line(colour = "black"),
    axis.ticks = element_line(),
    axis.text = element_text(size=12),
    axis.text.x = element_text(angle=30, hjust=1),
    legend.position = "none") +
  scale_x_continuous(minor_breaks = seq(1 , 7, 1), breaks = seq(1, 7, 1), labels = c('never', 'rarely', 'sometimes', 'about half', 'often', 'almost always', 'always')) +  
  scale_y_continuous(minor_breaks = seq(22, 58, 4), breaks = seq(22, 58, 4)) +
  geom_vline(xintercept=4)
```



```{r adult_directed, include = FALSE, fig.height=4, fig.width=3.8, fig.align = "left", num.cols.cap=1, fig.cap = "Looking at COCA data, these denisity plots show the usage amount based on the typicality of the adj-noun pair, seperated by the type of language (e.g., written)."}
adult_tokens <- read_csv("../../data/adult_tokens.csv")

adult_tokens$type <- factor(adult_tokens$type, levels=c("acad", "fic", "mag", "news", "spok"), labels=c("Academic \n Journals", "Fiction", "Magazines", "Newspapers", "Spoken \n(TV + radio)"))

adult_tokens %>%
  ggplot(aes(x=as.numeric(mean_typ), y=type, group=type, fill=type)) +
  geom_density_ridges2(scale=1.4) +
  ylab("Source of Adult Speech") +
  xlab("More Atypical                     More Typical \n Typicality of adjective-noun pairs") +
  theme_minimal() +
  theme(panel.grid = element_line(color="lightgrey",size=0.5),
    axis.line = element_line(colour = "black"),
    axis.ticks = element_line(),
    axis.text.x  = element_text(size=10, angle=30, hjust=1),
    axis.text.y = element_text(size=10, angle=25),
    legend.position = "none") +
  geom_vline(xintercept = 4) +
    scale_x_continuous(minor_breaks = seq(1 , 7, 1), breaks = seq(1, 7, 1), labels = c('never', 'rarely', 'sometimes', 'about half', 'often', 'almost always', 'always'))+
      scale_fill_brewer(palette = "Accent") 
```


# General Discussion

Language provides children a rich source of information about the world. However, this information is not always transparently available: language’s use to comment on the atypical and surprising means it does not perfectly mirror the world. Among adult conversational partners whose world knowledge is well-aligned, this characteristic of language allows people to converse informatively and not redundantly. But between a child and caregiver whose world knowledge is asymmetric, this pressure competes with other demands: what is minimally informative to an adult may be misleading to a child. In this work, we demonstrate that this pressure structures language to create a peculiar learning environment: one in which caregivers predominantly point out the atypical features of things. 

How, then, do children learn about the typical features of things from such an environment? While younger children may gain an importnat foothold from hearing more description of typical features, they still face language dominated by atypical description. Further when we looked at more nuanced ways... , we found that models of distributional semantics capture little typical feature information.

Of course, one source of information that may simplify this problem is perceptual information from the world itself. In many cases, perceptual information may swamp information from language; children likely see enough orange carrots in the world to outweigh hearing "purple carrot.” It remains unclear, however, how children learn about categories for which they have scarcer evidence. Indeed, language information likely swamps perceptual information for many other categories, such as abstract concepts or those that cannot be learned about by direct experience. Given that the present work is limited to concrete concepts, we can only speculate about the information caregivers provide about abstract concepts. But, if abstract concepts pattern similarly to concrete objects, children are in a particularly difficult bind. Though perceptual information is undoubtedly useful in learning about the typical features of things, it remains to be explained how children learn what is typical when this perceptual information is scant, irrelevant, or incomplete.

Another possibility is that children expect language to be used informatively at a young age. Under this hypothesis, their language environment is not misleading at all. If young children expect adjectives to mark atypical features, they can use description and the lack thereof to learn more about the world around them. Lab studies find that children expect interlocutors to be informative in relation to their prior knowledge by the age of 2 (Akhtar et al., 1996) and that 5–6-year-old children are roughly informative with respect to their interlocutor’s perspective in a referential communication task (Nadig & Sedivy, 2002). More naturalistic studies find that children at the one-word stage selectively imitate words that convey new information—that is, words that are informative with respect to what is obvious or assumed in the environment—when describing events (Greenfield & Zukow, 1978). The idea that young children understand the informative purpose of language is consistent with our finding that even young children also largely choose to describe atypical features. Though this effect can be explained by simpler means such as salience or mimicry, it suggests that caregivers and children may be usefully aligned in the aspects of the world they choose to talk about.

Whether adult-directed, child-directed, or a child's own speech, language is used with remarkable consistency: people talk about the atypical. Though parents might reasonably be broadly over-informative in order to teach their children about the world, this is not the case. This presents a potential puzzle for young learners who have limited world knowledge and limited pragmatic inferential abilities. Perceptual information and nascent pragmatic abilities may help fill in the gaps, but much remains to be explored to link these explanations to actual learning. Communication pressures are pervasive forces structuring the language children hear, and future work must disentangle whether children capitalize on them or are misled by them in learning about the world.

# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
